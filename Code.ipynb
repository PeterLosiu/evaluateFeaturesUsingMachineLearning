{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4de65b4b",
   "metadata": {},
   "source": [
    "# Evaluation of Stock Featues using Machine Learning Techniques\n",
    "\n",
    "The 'data mining' game started when CAPM was proposed in 1960s - the first factor model of return. And then in 1992, Fama and Frend proposed the famous 3 factor-models with factors including 'market return', 'size' (SMB), and 'book-to-market ratio' (HML). The game was unstoppable and investors try to 'dig' out factors that well explain the market. \n",
    "\n",
    "The traditional $MSE$ regression has several drawbacks, including:\n",
    "1. **Multi-collinearity**: features may interact with themselves, resulting in a lot of redundant features as well as large variance in coefficients\n",
    "2. **Over-fit**: it minimizes the bias with the cost of large variance\n",
    "3. **Hard to intepret** the resulting coefficients\n",
    "4. **Not a clear rule-set** to select features\n",
    "\n",
    "To adress all of these issues, we use the 3 famous regression models:\n",
    "1. **Ridge regression**: add a penalty term to the MSE argument to shrink the size of some coefficient, but keep all features. The penalty effect is controled by a constant that multiplies the penalty term - $L1$.\n",
    "2. **Lasso regression**: similar to Ridge, but allows coefficients to be zero, i.e. can remove some features. The penalty effect is controled by $L2$.\n",
    "3. **Elastic Net regression**: combination of the above two, but instead of controlling L1 and L2, we usually control the sum $L=L1+L2$ (the total effect of penalty) and the $L1-ratio=L1/L$ (the weight of Ridge's penalty).\n",
    "\n",
    "This project evaluates the prediction power of 44 different factors for all U.S. stocks listed on the NYSE, NASDAQ, or AMEX from 2018 to 2022. To ensure that all data is publicly available at the monthly timestamp and to prevent any lookahead bias, variables from columns 4 to 46 have been lagged by two months. Therefore, when performing a backtest, it is accurate to state, \"According to these numbers, I plan to buy the stocks at the beginning of next month.\"\n",
    "\n",
    "At the end, the 5 most effective factors are selected and interpreted in terms of their economical implication. \n",
    "\n",
    "**Data Source**: WRDS > CRSP/COMPUSTAT merged monthly (2018-2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f35b2382-500b-4a13-8076-baebb84555bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt # python's plotting package\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d99537b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:4359, train:14020, validation:4826.\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "validation = pd.read_csv(\"data/validation.csv\")\n",
    "print(f\"test:{len(test)}, train:{len(train)}, validation:{len(validation)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0953f839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "permno             93436.000000\n",
      "date              202012.000000\n",
      "ret                    0.243252\n",
      "rd_sale                0.087162\n",
      "equity_invcap         -0.535651\n",
      "npm                   -0.667802\n",
      "ps                     5.368845\n",
      "gprof                 -0.249735\n",
      "ptpm                  -0.671354\n",
      "aftret_eq              0.008141\n",
      "opmad                 -0.747909\n",
      "opmbd                 -0.696064\n",
      "gpm                   -0.687397\n",
      "debt_assets            0.280306\n",
      "sale_invcap           -0.006851\n",
      "adv_sale              -0.398256\n",
      "staff_sale            -0.385907\n",
      "de_ratio              -0.008646\n",
      "aftret_equity          0.008149\n",
      "capital_ratio          0.455894\n",
      "pcf                    4.213743\n",
      "accrual               -1.061972\n",
      "at_turn                0.065345\n",
      "lt_debt                0.115555\n",
      "debt_invcap            0.335739\n",
      "roa                   -0.207780\n",
      "capei                 -0.354029\n",
      "debt_at                0.563658\n",
      "totdebt_invcap         0.556521\n",
      "cash_debt             -0.506449\n",
      "evm                    0.369026\n",
      "cash_lt                0.229052\n",
      "debt_ebitda            0.035598\n",
      "lt_ppent              -0.260658\n",
      "roce                  -0.598561\n",
      "bm                    -1.028347\n",
      "ptb                    3.440549\n",
      "roe                   -0.345419\n",
      "aftret_invcapx        -0.402557\n",
      "sale_equity           -0.036602\n",
      "dltt_be               -0.014081\n",
      "rect_turn             -0.006938\n",
      "debt_capital           0.495434\n",
      "pe_exi                 6.979068\n",
      "pe_inc                 7.168529\n",
      "cfm                   -0.560686\n",
      "short_debt             0.651680\n",
      "Name: 14019, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train.iloc[len(train)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ef6b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"F-F_Research_Data_Factors.csv\")\n",
    "# RF = pd.DataFrame(data=data.query(\"201801<= date <= 202212\")[[\"date\",\"RF\"]], columns=[\"date\",\"RF\"]).reset_index(drop=True)\n",
    "# RF.to_csv(\"US_rf_rate.csv\")\n",
    "# https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html#Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c097a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = pd.read_csv(\"data/US_rf_rate.csv\")\n",
    "rf['RF_m'] = rf['RF']/12\n",
    "\n",
    "def calculate_premium(data):\n",
    "    \"\"\"\n",
    "    return a df with three more columns = ['RF','RF_m','premium']\n",
    "    \"\"\"\n",
    "    data = pd.merge(test, rf, on=\"date\", how='left').sort_values(by='date')\n",
    "    data['premium'] = data['ret'] - data['RF_m']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88a59eb",
   "metadata": {},
   "source": [
    "## 1. Calculate premium return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fdbb9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = calculate_premium(test)\n",
    "train_data = calculate_premium(train)\n",
    "valid_data = calculate_premium(validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74062c66",
   "metadata": {},
   "source": [
    "## 2. Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cdbce5",
   "metadata": {},
   "source": [
    "### Standardize all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c055a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63093304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized data\n",
    "def standardize(data: pd.DataFrame,scaler: StandardScaler = None):\n",
    "    scaled = data.copy()\n",
    "    scaled.iloc[:,3:47] = scaler.transform(scaled.iloc[:,3:47])\n",
    "    return scaled\n",
    "\n",
    "# initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data.iloc[:,3:47])\n",
    "\n",
    "test_data_stand = standardize(test_data, scaler)\n",
    "train_data_stand = standardize(train_data, scaler)\n",
    "valid_data_stand = standardize(valid_data, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7eee769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(train_data['premium'].values.reshape(-1, 1))\n",
    "\n",
    "test_data_stand['premium'] = scaler.transform(test_data['premium'].values.reshape(-1, 1)).ravel()\n",
    "train_data_stand['premium'] = scaler.transform(train_data['premium'].values.reshape(-1, 1)).ravel()\n",
    "valid_data_stand['premium'] = scaler.transform(valid_data['premium'].values.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de7c308f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature standard deviation: 0.9999999999999996\n",
      "Target festure standard deviation: 0.9999999999999983\n",
      "Feature mean: 8.5670716617929e-19\n",
      "Target feature mean: -6.5202361620564364e-18\n",
      "Standardization complete\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature standard deviation:\", np.mean(np.std(train_data_stand.iloc[:,3:47], axis=0)))\n",
    "print(\"Target festure standard deviation:\", np.std(train_data_stand['premium']))\n",
    "print(\"Feature mean:\", np.mean(np.mean(train_data_stand.iloc[:,3:47], axis=0)))\n",
    "print(\"Target feature mean:\", np.mean(train_data_stand['premium']))\n",
    "\n",
    "print(\"Standardization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ff7dce",
   "metadata": {},
   "source": [
    "### 2.1 Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "854ca757-2872-4fdf-a816-e935a0b7c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Ridge\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b55fcbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "train_data_scaled = scaler.fit_transform(train_data.iloc[:,3:47])\n",
    "valid_data_scaled = scaler.transform(valid_data.iloc[:,3:47])\n",
    "print(type(train_data_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3e73314-ddf3-42cf-af4f-42bdf861a7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The minimum mse is 0.9754538048762509, corresponding to lambda = 0.1.\n"
     ]
    }
   ],
   "source": [
    "# The alpha used by Python's ridge should be the lambda in Hull's book times the number of observations, i.e.the number of observation in training set\n",
    "# alphas=[0.1*num_train, 0.2*num_train,0.3*num_train,0.4*num_train,0.5*num_train,0.6*num_train,0.7*num_train,0.8*num_train,0.9*num_train,1*num_train]\n",
    "num_train = len(train_data_stand)\n",
    "alphas = [0.1*num_train*i for i in range(1,11)]\n",
    "mses=[]\n",
    "for alpha in alphas:\n",
    "    ridge=Ridge(alpha=alpha)\n",
    "    ridge.fit(train_data_stand.iloc[:,3:47].values,train_data_stand['premium'].values)\n",
    "    pred=ridge.predict(valid_data_stand.iloc[:,3:47].values)\n",
    "    mses.append(mse(valid_data_stand['premium'],pred))\n",
    "    # print(mse(valid_data_stand['premium'],pred))\n",
    "\n",
    "best_ridge_alpha = alphas[mses.index(min(mses))]/num_train\n",
    "\n",
    "print(f\"\\nThe minimum mse is {min(mses)}, corresponding to lambda = {best_ridge_alpha}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8483e64e",
   "metadata": {},
   "source": [
    "### 2.2 Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "393c01a8-e8cc-4412-bf50-26564e0d5320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Lasso\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83737922-24e2-4ba2-b9c3-475fc725d1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The minimum mse is 0.9709377858509662, corresponding to lambda = 0.001.\n"
     ]
    }
   ],
   "source": [
    "# We now consider different lambda values. The alphas are half the lambdas\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# alphas = [0.001/2, 0.002/2,0.003/2,0.004/2,0.005/2,0.006/2,0.007/2,0.008/2,0.009/2,0.01/2]\n",
    "alphas = [0.001, 0.002,0.003,0.004,0.005,0.006,0.007,0.008,0.009,0.01]\n",
    "mses = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(train_data_stand.iloc[:,3:47].values,train_data_stand['premium'].values)\n",
    "    pred = lasso.predict(valid_data_stand.iloc[:,3:47].values)\n",
    "    mse_value = mean_squared_error(valid_data_stand['premium'], pred)\n",
    "    mses.append(mse_value)\n",
    "    # print(mse_value)\n",
    "\n",
    "best_lasso_alpha = alphas[mses.index(min(mses))]\n",
    "\n",
    "print(f\"\\nThe minimum mse is {min(mses)}, corresponding to lambda = {alphas[mses.index(min(mses))]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b488a1",
   "metadata": {},
   "source": [
    "### 2.3 Elestic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1763f4a-1be6-45d1-8bab-511f3b9cf02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Elastic Net\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c02dc60c-b585-4739-9548-6de9e5e579d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Best Parametors ===\n",
      "Best Alpha: 0.001000\n",
      "Best L1 Ratio: 0.1\n",
      "Best MSE: 0.970474\n"
     ]
    }
   ],
   "source": [
    "# alphas = [0.001/2, 0.002/2,0.003/2,0.004/2,0.005/2,0.006/2,0.007/2,0.008/2,0.009/2,0.01/2]\n",
    "lambdas = [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01]\n",
    "l1_ratios = [0.1, 0.5, 0.9, 0.2, 0.7]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Train model and calculate MSE\n",
    "for alpha in lambdas:\n",
    "    for l1_ratio in l1_ratios:\n",
    "        elastic_net = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "        elastic_net.fit(train_data_stand.iloc[:,3:47].values,train_data_stand['premium'].values)\n",
    "        pred = elastic_net.predict(valid_data_stand.iloc[:,3:47].values)\n",
    "        error = mean_squared_error(valid_data_stand['premium'], pred)\n",
    "        results.append((alpha, l1_ratio, error))\n",
    "        # print(f\"Alpha: {alpha}, L1 Ratio: {l1_ratio}, MSE: {error}\")\n",
    "\n",
    "# 找到最佳参数\n",
    "best_result = min(results, key=lambda x: x[2])\n",
    "best_en_alpha, best_en_l1_ratio, best_mse = best_result\n",
    "\n",
    "\n",
    "print(f\"\\n=== Best Parametors ===\")\n",
    "print(f\"Best Alpha: {best_en_alpha:.6f}\")\n",
    "print(f\"Best L1 Ratio: {best_en_l1_ratio}\")\n",
    "print(f\"Best MSE: {best_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a2a79",
   "metadata": {},
   "source": [
    "## 3. Choose the best model based on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88069bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Individual Model Performance on Test Set ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Applications\\Coding\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Applications\\Coding\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but Lasso was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         Model       MSE        R²                 Parameters\n",
      "0        Ridge  0.970432  0.029568    alpha=0.1, l1_ratio=N/A\n",
      "1        Lasso  0.970938  0.029062  alpha=0.001, l1_ratio=1.0\n",
      "2  Elastic Net  0.970474  0.029526  alpha=0.001, l1_ratio=0.1\n",
      "\n",
      "The best model with lowest MSE is Ridge\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Applications\\Coding\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but ElasticNet was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initiate the three models with the best (least MSE) alphas\n",
    "ridge_best = Ridge(alpha=best_ridge_alpha, random_state=42)\n",
    "lasso_best = Lasso(alpha=best_lasso_alpha, random_state=42, max_iter=10000)\n",
    "elastic_net_best = ElasticNet(alpha=best_en_alpha, l1_ratio=best_en_l1_ratio, \n",
    "                             random_state=42, max_iter=10000)\n",
    "\n",
    "models = {\n",
    "    'Ridge': ridge_best,\n",
    "    'Lasso': lasso_best, \n",
    "    'Elastic Net': elastic_net_best\n",
    "}\n",
    "\n",
    "X_test = test_data_stand.iloc[:,3:47]\n",
    "y_test = test_data_stand['premium'].values\n",
    "\n",
    "# store the results\n",
    "results = []\n",
    "\n",
    "print(\"\\n=== Individual Model Performance on Test Set ===\\n\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    # re-train the models\n",
    "    model.fit(train_data_stand.iloc[:,3:47].values, train_data_stand['premium'].values)\n",
    "    \n",
    "    # predict on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # calculate MSE and r2 score\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'MSE': mse,\n",
    "        'R²': r2,\n",
    "        'Parameters': f\"alpha={getattr(model, 'alpha', 'N/A')}, l1_ratio={getattr(model, 'l1_ratio', 'N/A')}\"\n",
    "    })\n",
    "    \n",
    "    # print(f\"{name}:\")\n",
    "    # print(f\"  MSE: {mse:.6f}\")\n",
    "    # print(f\"  R²: {r2:.4f}\")\n",
    "    # if hasattr(model, 'l1_ratio'):\n",
    "        # print(f\"  Parameters: alpha={model.alpha:.6f}, l1_ratio={model.l1_ratio}\")\n",
    "    # else:\n",
    "        # print(f\"  Parameters: alpha={model.alpha:.6f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print('\\n'+results_df.to_string())\n",
    "print(f\"\\nThe best model with lowest MSE is {min(results, key=lambda x: x['MSE'])['Model']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbd4efb",
   "metadata": {},
   "source": [
    "## 4. Coefficient Evaluation for the Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bebe63",
   "metadata": {},
   "source": [
    "$1 / (2 * n_{samples}) * ||y - Xw||^2_2 + alpha * l1_{ratio} * ||w||_1 + 0.5 * alpha * (1 - l1_{ratio}) * ||w||^2_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8bf1d8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Best Model Coefficients Analysis ===\n",
      "Best Model: ElasticNet\n",
      "Number of features: 44\n",
      "Non-zero coefficients: 44\n",
      "Sparsity: 100.0%\n",
      "\n",
      "All Coefficients (sorted by absolute value):\n",
      "      Feature  Coefficient  Abs_Coefficient\n",
      "equity_invcap    -0.189142         0.189142\n",
      "        opmbd     0.187162         0.187162\n",
      "          evm    -0.180207         0.180207\n",
      "      debt_at    -0.162934         0.162934\n",
      "          roa     0.156375         0.156375\n",
      "  debt_ebitda     0.146821         0.146821\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=== Best Model Coefficients Analysis ===\")\n",
    "\n",
    "best_model = elastic_net_best\n",
    "\n",
    "# re-train to get the coeficients\n",
    "best_model.fit(train_data_stand.iloc[:,3:47].values, train_data_stand['premium'].values)\n",
    "\n",
    "# predict on the test data\n",
    "X_test = test_data_stand.iloc[:,3:47].values\n",
    "y_test = test_data_stand['premium'].values\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# grab coef\n",
    "coefficients = best_model.coef_\n",
    "feature_names = test_data_stand.columns[3:47]\n",
    "\n",
    "# create DataFrame for coef\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients,\n",
    "    'Abs_Coefficient': np.abs(coefficients)\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(f\"Best Model: {type(best_model).__name__}\")\n",
    "print(f\"Number of features: {len(coef_df)}\")\n",
    "print(f\"Non-zero coefficients: {np.sum(coefficients != 0)}\")\n",
    "print(f\"Sparsity: {np.sum(coefficients != 0) / len(coefficients) * 100:.1f}%\")\n",
    "\n",
    "print(\"\\nAll Coefficients (sorted by absolute value):\")\n",
    "print(coef_df.iloc[0:6].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9806eb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TOP 5 MOST SIGNIFICANT FACTORS INFLUENCING STOCK RETURNS\n",
      "======================================================================\n",
      "\n",
      "#1: equity_invcap\n",
      "   Coefficient: -0.189142\n",
      "   Absolute Impact: 0.189142\n",
      "   Direction: Negative relationship with returns\n",
      "\n",
      "#2: opmbd\n",
      "   Coefficient: 0.187162\n",
      "   Absolute Impact: 0.187162\n",
      "   Direction: Positive relationship with returns\n",
      "\n",
      "#3: evm\n",
      "   Coefficient: -0.180207\n",
      "   Absolute Impact: 0.180207\n",
      "   Direction: Negative relationship with returns\n",
      "\n",
      "#4: debt_at\n",
      "   Coefficient: -0.162934\n",
      "   Absolute Impact: 0.162934\n",
      "   Direction: Negative relationship with returns\n",
      "\n",
      "#5: roa\n",
      "   Coefficient: 0.156375\n",
      "   Absolute Impact: 0.156375\n",
      "   Direction: Positive relationship with returns\n"
     ]
    }
   ],
   "source": [
    "# grab the top 5 features with highest weights\n",
    "top_5_factors = coef_df.head(5).copy()\n",
    "top_5_factors['Rank'] = range(1, 6)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOP 5 MOST SIGNIFICANT FACTORS INFLUENCING STOCK RETURNS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, (idx, row) in enumerate(top_5_factors.iterrows(), 1):\n",
    "    print(f\"\\n#{i}: {row['Feature']}\")\n",
    "    print(f\"   Coefficient: {row['Coefficient']:.6f}\")\n",
    "    print(f\"   Absolute Impact: {row['Abs_Coefficient']:.6f}\")\n",
    "    print(f\"   Direction: {'Positive' if row['Coefficient'] > 0 else 'Negative'} relationship with returns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a915fa8",
   "metadata": {},
   "source": [
    "## 5. Economic Interpretations of the Top 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c315122",
   "metadata": {},
   "source": [
    "### 1: evm: Multiple of Enterprise Value to EBITDA\n",
    "Economic Interpretation: Higher EVM predicts lower returns, implying that companies with elevated EV/EBITDA ratios should be avoided. It is important to invest in companies that have reasonable prices relative to their operating earnings.\n",
    "### 2: opmbd: Operating Income before Depreciation as a Fraction of Sales\n",
    "Economic Interpretation: Companies with higher operating profit margins are expected to deliver superior returns since this factor reflects the company's economic moat and pricing power. It suggests seeking companies with strong and sustainable operating margins.\n",
    "### 3: equity_invcap: Common Equity/Invested Capital\n",
    "Economic Interpretation: Higher equity proportion in capital structure predicts lower returns. Over-reliance on equity financing may dilute returns, while reasonable debt leverage with careful risk management can increase capital efficiency. This may also indicate immature companies with less established credit capacity. Therefore, we prefer companies with balanced capital structures.\n",
    "### 4: debt_ebitda: Total Debt/EBITDA\n",
    "Economic Interpretation: This factor reinforces the economic interpretation of factor three from a debt perspective, suggesting that higher debt levels yield higher predicted stock returns. This could be due to efficient use of financial leverage which enhances shareholder returns. However, it is worth noting that excessive leverage should be avoided.\n",
    "### 5: ps: Multiple of Market Value of Equity to Sales\n",
    "Economic Interpretation: Higher price-to-sales multiples predict better performance, which seems counterintuitive to value investing. However, we should take growth expectations into consideration because the market pays a premium for return potential. Therefore, valuation naturally varies with revenue quality and growth prospects, which positively correlate with returns.\n",
    "Conclusion: We believe these factors generally correspond with well-known trading strategies, such as Warren Buffett's value investment approach. Value investing considers profitability (opmbd), overvaluation (evm), and financial health (debt_ebitda and equity_invcap), which is consistent with four out of the five most important factors in our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
